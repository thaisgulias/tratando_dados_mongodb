{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pRfc5h8lSc1s"
      ],
      "authorship_tag": "ABX9TyMsGAmBib1T2bLHMeps1Abf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Instalações e arquivos\n"
      ],
      "metadata": {
        "id": "RcOFqxx56xsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pymongo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJd-sWF7SywN",
        "outputId": "8d16fb3d-0140-4712-e5db-f328d7ee4291",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.7.0 pymongo-4.10.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install paramiko"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cSYbG9pS1oG",
        "outputId": "72aa046e-a918-4004-cd3f-4de23300b4b1",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting paramiko\n",
            "  Downloading paramiko-3.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting bcrypt>=3.2 (from paramiko)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko) (43.0.3)\n",
            "Collecting pynacl>=1.5 (from paramiko)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko) (2.22)\n",
            "Downloading paramiko-3.5.0-py3-none-any.whl (227 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bcrypt, pynacl, paramiko\n",
            "Successfully installed bcrypt-4.2.0 paramiko-3.5.0 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sshtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7xLQ-MHS3Jx",
        "outputId": "6f791500-af47-491f-b34d-4ad2e3fdeb4a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sshtunnel\n",
            "  Downloading sshtunnel-0.4.0-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: paramiko>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from sshtunnel) (3.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.2 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.7.2->sshtunnel) (4.2.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.7.2->sshtunnel) (43.0.3)\n",
            "Requirement already satisfied: pynacl>=1.5 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.7.2->sshtunnel) (1.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.7.2->sshtunnel) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.7.2->sshtunnel) (2.22)\n",
            "Downloading sshtunnel-0.4.0-py2.py3-none-any.whl (24 kB)\n",
            "Installing collected packages: sshtunnel\n",
            "Successfully installed sshtunnel-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import subprocess\n",
        "import time\n",
        "import pymongo\n",
        "import paramiko\n",
        "import json\n",
        "from sshtunnel import SSHTunnelForwarder\n",
        "from pymongo import MongoClient\n",
        "from bson.objectid import ObjectId\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "U_igU72uS5i6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "38g2E7_fafmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "server = SSHTunnelForwarder(\n",
        "    '',\n",
        "    ssh_username=\"thais_gulias\",\n",
        "    ssh_pkey =\"/content/thais_gulias\",\n",
        "    remote_bind_address=('', 27017),\n",
        "    local_bind_address=('localhost', 27017)\n",
        ")\n",
        "\n",
        "server.start()\n",
        "\n",
        "print(server.local_bind_port)  # show assigned local port\n",
        "# tunel com ssh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5xKXZMFS7aA",
        "outputId": "8761ca26-9a8f-4f36-a5af-82c1b862423d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# URI de conexão com o MongoDB\n",
        "uri = \"\"\n",
        "\n",
        "# Conectando ao MongoDB\n",
        "try:\n",
        "    client = pymongo.MongoClient(uri)\n",
        "    print(\"Conexão com o MongoDB estabelecida com sucesso!\")\n",
        "except pymongo.errors.ConnectionFailure:\n",
        "    print(\"Não foi possível conectar ao MongoDB. Verifique se o servidor está em execução.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVUkfX2HS9eF",
        "outputId": "e4dfc35a-cc56-4598-d574-fe2d0fa9bf40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conexão com o MongoDB estabelecida com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if client:\n",
        "        # Acessar o banco de dados 'worflows'\n",
        "        db = client ['workflows']\n",
        "\n",
        "\n",
        "        # Acesse diretamente as coleções desejadas\n",
        "workflows_collection = db['workflows']\n",
        "workflowsitems_collection = db['workflowsItems']\n",
        "marketplaces_collection = db['marketplaces']\n",
        "scheduledbookings_collection = db['scheduledbookings']\n",
        "schedules_collection = db['schedules']\n",
        "workflowitemrelations_collection = db['workflowitemrelations']"
      ],
      "metadata": {
        "id": "Qk0mopNaTAEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DADOS"
      ],
      "metadata": {
        "id": "tZEsSWWI67pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir a query no workflowsitems_collection\n",
        "workflow_id = ObjectId(\"teste\")\n",
        "query_items = { \"workflowId\": workflow_id }\n",
        "workflow_items = workflowsitems_collection.find(query_items)\n",
        "\n",
        "# Converter em DataFrame\n",
        "workflow_items_df = pd.DataFrame(list(workflow_items))\n",
        "workflow_items_df"
      ],
      "metadata": {
        "id": "hnZsG-ZSZt9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FECHAR"
      ],
      "metadata": {
        "id": "VYc-_E4abR94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fechar tunel SSH\n",
        "server.stop()"
      ],
      "metadata": {
        "id": "atF0n2kvZOMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Fechar a conexão com o MongoDB\n",
        "client.close()\n"
      ],
      "metadata": {
        "id": "_9bdMaoIX3Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para remover os últimos 9 caracteres do campo 'field'\n",
        "def remove_last_9_chars(field_name):\n",
        "    return field_name[:-9] if isinstance(field_name, str) else field_name\n",
        "\n",
        "# Aplicar a transformação para remover os últimos 9 caracteres do 'field' para cada item dentro da lista de dicionários\n",
        "for index, row in workflow_items_df.iterrows():\n",
        "    workflow_items_df.at[index, 'data'] = [\n",
        "        {'field': remove_last_9_chars(item['field']), 'value': item.get('value', None)} for item in row['data']\n",
        "    ]\n",
        "\n",
        "# Criar um DataFrame onde 'field' se torna colunas e 'value' são os valores dessas colunas\n",
        "transformed_df = pd.DataFrame([\n",
        "    {item['field']: item.get('value', None) for item in row}\n",
        "    for row in workflow_items_df['data']\n",
        "])\n",
        "\n",
        "# Expandir o campo de endereço 'endereco_de_residencia_do_requerente' para várias colunas\n",
        "if 'endereco_de_residencia_do_requerente' in transformed_df.columns:\n",
        "    endereco_df = pd.json_normalize(transformed_df['endereco_de_residencia_do_requerente'])\n",
        "    # Unir as novas colunas ao DataFrame original e remover a coluna aninhada original\n",
        "    transformed_df = pd.concat([transformed_df.drop(columns=['endereco_de_residencia_do_requerente']), endereco_df], axis=1)\n"
      ],
      "metadata": {
        "id": "GnxwHylEcBpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituir valores que representam NaN por np.nan\n",
        "transformed_df.replace(['None', 'none', 'NULL', 'null', 'nan', ''], np.nan, inplace=True)\n",
        "# Substitui NaN por uma string vazia\n",
        "transformed_df.fillna('', inplace=True)\n"
      ],
      "metadata": {
        "id": "tLvE1vJzvBhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de colunas a serem limpas\n",
        "cols_to_clean = ['data_de_nascimento', 'data_de_nascimento_doa_estudante','data_de_nascimento_do_irmao']\n",
        "\n",
        "# Aplicando a limpeza em cada coluna da lista com substituições encadeadas\n",
        "for col in cols_to_clean:\n",
        "    transformed_df[col] = (transformed_df[col]\n",
        "                           .str.replace('T03:00:00.000Z', '', regex=False)\n",
        "                           .str.replace('T02:00:00.000Z', '', regex=False))"
      ],
      "metadata": {
        "id": "7T4s2eR0KB3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover colchetes, chaves e aspas simples de todos os elementos do DataFrame, tratando valores nulos e entradas não-string\n",
        "transformed_df = transformed_df.apply(lambda col: col.astype(str).str.replace('[', '', regex=False)\n",
        "                                                        .str.replace(']', '', regex=False)\n",
        "                                                        .str.replace('{', '', regex=False)\n",
        "                                                        .str.replace('}', '', regex=False)\n",
        "                                                        .str.replace(\"'\", '') if col.dtype == 'object' else col)\n"
      ],
      "metadata": {
        "id": "Nyl8v0NHLPM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_df['email_para_contato'] = transformed_df['email_para_contato'].str.replace('email: ', '', regex=False)"
      ],
      "metadata": {
        "id": "m4ck_PQ0bIq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrando as colunas que começam com o prefixo 'escolha_a_escola_destino'\n",
        "cols_to_combine = transformed_df.filter(like='escolha_a_escola_destino')\n",
        "\n",
        "# Concatenando as colunas em uma nova coluna, ignorando NaN e valores vazios\n",
        "transformed_df['escolas_destino'] = cols_to_combine.apply(\n",
        "    lambda x: ', '.join([val for val in x.dropna().astype(str) if val.strip()]), axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "2UpWKO8JqIQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraindo o bairro (a parte após o segundo traço)\n",
        "transformed_df['bairro_escola'] = transformed_df['escolas_destino'].str.split(' - ').str[-1].str.strip()"
      ],
      "metadata": {
        "id": "hceAafDCyuh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_combine_curso = transformed_df.filter(like='o_estudante_ira_cursar')\n",
        "\n",
        "# Concatenando as colunas em uma nova coluna, ignorando NaN e valores vazios\n",
        "transformed_df['ano_escolar_destino'] = cols_to_combine_curso.apply(\n",
        "    lambda x: ', '.join([val for val in x.dropna().astype(str) if val.strip()]), axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "FkvkgyDfq7Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_drop = transformed_df.filter(like='o_estudante_ira_cursar').columns.tolist() + \\\n",
        "               transformed_df.filter(like='escolha_a_escola_destino').columns.tolist()\n",
        "\n",
        "# Removendo as colunas filtradas\n",
        "transformed_df.drop(cols_to_drop, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "jFsBImmozYXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adicionando a coluna 'protocol' do workflow_items_df ao transformed_df\n",
        "transformed_df['protocol'] = workflow_items_df['protocol']"
      ],
      "metadata": {
        "id": "bWRh59Fpyaxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}